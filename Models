#KNN CLASSIFIER
from sklearn.neighbors import KNeighborsClassifier
#Setup arrays to store training and test accuracies
neighbors = np.arange(1,9)
train_accuracy =np.empty(len(neighbors))
test_accuracy = np.empty(len(neighbors))
for i,k in enumerate(neighbors):
    #Setup a knn classifier with k neighbors
    knn = KNeighborsClassifier(n_neighbors=k, n_jobs=-1)
    #Fit the model
    knn.fit(x_train, y_train)
    #Compute accuracy on the training set
    train_accuracy[i] = knn.score(x_train, y_train)
        #Compute accuracy on the test set
    test_accuracy[i] = knn.score(x_test, y_test)
print_scores(knn, x_train, y_train, 10, 'accuracy')
plt.title('KNN Varying number of neighbors')
plt.plot(neighbors, test_accuracy, label='Testing Accuracy')
plt.plot(neighbors, train_accuracy, label='Training accuracy')
plt.legend()
plt.xlabel('Number of neighbors')
plt.ylabel('Accuracy')
plt.show()
knn = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)
knn.fit(x_train,y_train)
y_pred_knn = knn.predict(x_test)
print('Classification Report', classification_report(y_test, y_pred_knn))
print('Confusion Matrix', confusion_matrix(y_test, y_pred_knn))
print("Training Accuracy", knn.score(x_train, y_train)*100)
print("Testing Accuracy", knn.score(x_test, y_test)*100)
score_knn = round(accuracy_score(y_pred_knn,y_test)*100,2)
print("The accuracy score achieved using KNN Model is: "+str(score_knn)+" %")
from sklearn import neighbors
from sklearn.metrics import mean_squared_error 
from math import sqrt
pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)
#HYPERPARAMTER-TUNING
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import time
from sklearn import preprocessing
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import GridSearchCV,RandomizedSearchCV
from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score
df = pd.read_csv(r"C:\Users\Divya Haridas\Desktop\cancer.csv")
df.head()
x = df.iloc[:, :-1].values
print(x)
y = df.iloc[:, -1].values
print(y)
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=42, stratify=y)
from sklearn.metrics import scorer
from time import time
knn = KNeighborsClassifier()
params = {'n_neighbors':range(2,11),'metric':['minkowski','manhattan','euclidean']}
grid_search = GridSearchCV(knn,param_grid = params,scoring='precision',cv=2)
grid_search.fit(x_train,y_train)
print("Grid Search Results\n \n")
print("Best Params : ",grid_search.best_params_)
print("Best Precision : ",grid_search.best_score_)
print("Best Model: \n",grid_search.best_estimator_)
knn = KNeighborsClassifier()
params = {'n_neighbors':np.arange(2,11,step=1),'metric':['minkowski','manhattan','euclidean']}
random_search = RandomizedSearchCV(knn,params,scoring='precision' ,cv=2)
random_search.fit(x_train,y_train)
print("Random Search Results")
print("Best Params : ",random_search.best_params_)
print("Best Precision : ",random_search.best_score_)
print("Best Model: \n",random_search.best_estimator_)
tuned_model = random_search.best_estimator_
y_pred = tuned_model.predict(x_test).flatten()
print("Fine Tuned Model results\n\n")
conf_mat=confusion_matrix(y_test,y_pred)
print("Confusion Matrix \n",conf_mat)
print("\nClassification Report : \n",classification_report(y_test,y_pred))
tuned_accuracy = (conf_mat[0][0]+conf_mat[1][1])/len(y_test)
print("Accuracy : " ,tuned_accuracy )
probs=tuned_model.predict_proba(x_test)
probs=probs[:,1]
fpr,tpr,_=roc_curve(y_test,probs)
random_probs = [0 for _ in range(len(y_test))]
p_fpr,p_tpr,_ = roc_curve(y_test,random_probs)
auc_score=roc_auc_score(y_test,probs)
print("AUC SCORE : " ,auc_score)
plt.plot(p_fpr, p_tpr, linestyle='--')
plt.plot(fpr, tpr, marker='.', label='TUNED KNN (area=%0.2f)'% auc_score)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title("ROC-AUC CURVE for TUNED KNN Classifier")
plt.legend()
plt.show()

#NBC CLASSIFIER
from sklearn.naive_bayes import GaussianNB
nb = GaussianNB()
print_scores(nb, x_train, y_train, 10, 'accuracy')
nb.fit(x_train,y_train)
y_pred_nb = nb.predict(x_test)
print('Classification Report', classification_report(y_test, y_pred_nb))
print('Confusion Matrix', confusion_matrix(y_test, y_pred_nb))
print("Training Accuracy", nb.score(x_train, y_train)*100)
print("Testing Accuracy", nb.score(x_test, y_test)*100)
score_nb = round(accuracy_score(y_pred_nb,y_test)*100,2)
print("The accuracy score achieved using Naive Bayes Model is: "+str(score_nb)+" %")

#DECISION TREE CLASSIFIER
from sklearn.tree import DecisionTreeClassifier as DTC
classifier = DTC(criterion = 'entropy', random_state = 0)
classifier.fit(x_train, y_train)
dtc = DTC()
dtc.fit(x_train,y_train)
#MODEL PERFORMANCE EVALUATION
from sklearn.metrics import classification_report,confusion_matrix
x_test = np.nan_to_num(x_test)
y_pred = dtc.predict(x_test)
print(classification_report(y_test,y_pred))
conf_mat = confusion_matrix(y_test,y_pred)
print("Confusion Matrix: ",(conf_mat))
print("Accuracy : ",(conf_mat[0][0]+conf_mat[1][1])/len(y_test))
#VISUALIZATION
from os import system
from sklearn.ensemble import RandomForestClassifier
model = RandomForestClassifier(n_estimators=690)
# Train
model.fit(x_train, y_train.ravel())
# Extract single tree
estimator = model.estimators_[5]
from sklearn.tree import export_graphviz
from sklearn import tree
# Export as dot file
dotfile = open("C:/Users/NANDHINI SIVAKUMAR/Downloads/treedf.dot", 'w')
export_graphviz(estimator, out_file="C:/Users/NANDHINI SIVAKUMAR/Downloads/treedf.dot")
dotfile.close()
system("dot -Tpng C:/Users/NANDHINI SIVAKUMAR/Downloads/treedf.dot -o C:/Users/NANDHINI SIVAKUMAR/Downloads/treedf.png")
from graphviz import Source
from IPython.display import SVG
tree.export_graphviz(estimator, out_file="C:/Users/NANDHINI SIVAKUMAR/Downloads/treedf.dot", feature_names=None)
system('C:/Users/NANDHINI SIVAKUMAR/anaconda3/Lib/site-packages/graphviz/')
tree.plot_tree(estimator,feature_names = None)
#HYPER-PARAMETER TUNING
def Snippet_146_Ex_2():
    print('**Optimizing hyper-parameters of a Decision Tree model using Grid Search in Python**\n')
    # Creating an standardscaler object
    std_slc = StandardScaler()
    # Creating a pca object
    pca = decomposition.PCA()
    # Creating a DecisionTreeClassifier
    dec_tree = tree.DecisionTreeClassifier()
    # Creating a pipeline of three steps. First, standardizing the data.
    # Second, tranforming the data with PCA.
    # Third, training a Decision Tree Classifier on the data.
    pipe = Pipeline(steps=[('std_slc', std_slc),('pca', pca),('dec_tree', dec_tree)])
    # Creating Parameter Space
    # Creating a list of a sequence of integers from 1 to 30 (the number of features in X + 1)
    n_components = list(range(1,X.shape[1]+1,1))
    # Creating lists of parameter for Decision Tree Classifier
    criterion = ['gini', 'entropy']
    max_depth = [2,4,6,8,10,12]
    # Creating a dictionary of all the parameter options 
    # Note that we can access the parameters of steps of a pipeline by using '__â€™
    parameters = dict(pca__n_components=n_components,dec_tree__criterion=criterion,dec_tree__max_depth=max_depth)
    # Conducting Parameter Optmization With Pipeline
    # Creating a grid search object
    clf_GS = GridSearchCV(pipe, parameters)
    # Fitting the grid search
    clf_GS.fit(X, Y)
    # Viewing The Best Parameters
    print('Best Criterion:', clf_GS.best_estimator_.get_params()['dec_tree__criterion'])
    print('Best max_depth:', clf_GS.best_estimator_.get_params()['dec_tree__max_depth'])
    print('Best Number Of Components:', clf_GS.best_estimator_.get_params()['pca__n_components'])
    print(); print(clf_GS.best_estimator_.get_params()['dec_tree'])
Snippet_146_Ex_2()

#RANDOM FOREST CLASSIFIER
from sklearn.ensemble import RandomForestClassifier as RTC
classifier = RTC(n_estimators = 10, criterion = 'entropy', random_state = 0)
classifier.fit(x_train, y_train)
rtc = RTC()
rtc.fit(x_train,y_train)
#MODEL PERFORMANCE EVALUATION
from sklearn.metrics import classification_report,confusion_matrix
x_test = np.nan_to_num(x_test)
y_pred = rtc.predict(x_test)
print(classification_report(y_test,y_pred))
conf_mat = confusion_matrix(y_test,y_pred)
print("Confusion Matrix: ",(conf_mat))
print("Accuracy : ",(conf_mat[0][0]+conf_mat[1][1])/len(y_test))
#VISUALIZATION
from os import system
from sklearn.ensemble import RandomForestClassifier
model = RandomForestClassifier(n_estimators=690)
# Train
model.fit(x_train, y_train.ravel())
# Extract single tree
estimator = model.estimators_[5]
from sklearn.tree import export_graphviz
from sklearn import tree
# Export as dot file
dotfile = open("C:/Users/NANDHINI SIVAKUMAR/Downloads/treerf.dot", 'w')
export_graphviz(estimator, out_file="C:/Users/NANDHINI SIVAKUMAR/Downloads/treerf.dot")
dotfile.close()
system("dot -Tpng C:/Users/NANDHINI SIVAKUMAR/Downloads/treerf.dot -o C:/Users/NANDHINI SIVAKUMAR/Downloads/treerf.png")
from graphviz import Source
from IPython.display import SVG
tree.export_graphviz(estimator, out_file="C:/Users/NANDHINI SIVAKUMAR/Downloads/treerf.dot", feature_names=None)
system('C:/Users/NANDHINI SIVAKUMAR/anaconda3/Lib/site-packages/graphviz/')
tree.plot_tree(estimator,feature_names = None)

#FACTOR ANALYSIS
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
np.array(list(dt.columns),dtype=object)
dt.isnull().sum()
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
df = scaler.fit_transform(dt)
df = pd.DataFrame(data=df,columns=dt.columns)
df.head()
#BARTLETT AND KMO TEST
from factor_analyzer.factor_analyzer import calculate_bartlett_sphericity,calculate_kmo
chi2,p = calculate_bartlett_sphericity(df)
print("Chi squared value : ",chi2)
print("p value : ",p)
kmo_all,kmo_model = calculate_kmo(dt)
print("KMO Test value: ",kmo_model)
#DETERMINING NUMBER OF FACTORS AND SCREE PLOT
from factor_analyzer import FactorAnalyzer
fa = FactorAnalyzer(rotation = None,impute = "drop",n_factors=df.shape[1])
fa.fit(df)
ev,_ = fa.get_eigenvalues()
plt.scatter(range(1,df.shape[1]+1),ev)
plt.plot(range(1,df.shape[1]+1),ev)
plt.title('Scree Plot')
plt.xlabel('Factors')
plt.ylabel('Eigen Value')
plt.grid()
#EIGEN VALUES, FACTOR LOADINGS, UNIQUENESS BY FACTOR ANALYSIS
fa = FactorAnalyzer(n_factors=6,rotation='varimax')
fa.fit(dt)
with np.printoptions(suppress=True,precision=6):
    print("Factor Loadings:")
    print(pd.DataFrame(fa.loadings_,index=df.columns))
with np.printoptions(suppress=True,precision=6):
    print("Variance:")
    print(pd.DataFrame(fa.get_factor_variance(),index=['Eigen Values','Proportional Var','Cumulative Var']))
with np.printoptions(suppress=True,precision=6):
    print("Uniqueness:")
    print(pd.DataFrame(fa.get_uniquenesses(),index=df.columns,columns=['Uniqueness']))
with np.printoptions(precision=4,suppress=True):
    print("Eigen values:")
    print(pd.DataFrame(fa.get_communalities(),index=df.columns,columns=['Communalities']))

#SUPPORT VECTOR MACHINE
dt = pd.read_excel('C:/Users/SRS/Downloads/cancer patient data sets.xlsx')
x=dt.iloc[:,1].values.reshape(-1,1)
y=dt.iloc[:,-1]
X_train,X_test,Y_train,Y_test = train_test_split(x,y,test_size=0.15,random_state=101)
#using linear kernel
from sklearn import svm
sv = svm.SVC(kernel='linear')
print_scores(sv, X_train, Y_train, 10, 'accuracy')
sv.fit(X_train, Y_train)
Y_pred_svm = sv.predict(X_test)
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
print('Classification Report', classification_report(Y_test, Y_pred_svm))
print('Confusion Matrix', confusion_matrix(Y_test, Y_pred_svm))
print("Training Accuracy", sv.score(X_train, Y_train)*100)
print("Testing Accuracy", sv.score(X_test, Y_test)*100)
from sklearn.metrics import accuracy_score
score_svm = round(accuracy_score(Y_pred_svm,Y_test)*100,2)
print("The accuracy score achieved using Linear SVM Model is: "+str(score_svm)+" %")
#using radial basis kernel
from sklearn import svm
sv = svm.SVC(kernel= 'rbf')
print_scores(sv, X_train, Y_train, 10, 'accuracy')
sv.fit(X_train, Y_train)
Y_pred_svm = sv.predict(X_test)
print('Classification Report', classification_report(Y_test, Y_pred_svm))
print('Confusion Matrix', confusion_matrix(Y_test, Y_pred_svm))
print("Training Accuracy", sv.score(X_train, Y_train)*100)
print("Testing Accuracy", sv.score(X_test, Y_test)*100)
score_svm = round(accuracy_score(Y_pred_svm,Y_test)*100,2)
print("The accuracy score achieved using Linear SVM Model is: "+str(score_svm)+" %")
#HYPER-PARAMETER TUNING
from sklearn.model_selection import GridSearchCV 
from sklearn.svm import SVC 
from sklearn.metrics import classification_report, confusion_matrix 
# defining parameter range 
param_grid = {'C': [0.1, 1, 10, 100, 1000],  'gamma': [1, 0.1, 0.01, 0.001, 0.0001],              'kernel': ['rbf']}  
  grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3) 
from sklearn.model_selection import train_test_split 
X_train, X_test, Y_train, Y_test = train_test_split( X,Y, test_size = 0.30, random_state = 101) 
  # fitting the model for grid search 
grid.fit(X_train, Y_train) 
# print best parameter after tuning 
print(grid.best_params_) 
  # print how our model looks after hyper-parameter tuning 
print(grid.best_estimator_) 
grid_predictions = grid.predict(X_test) 
# print classification report 
print(classification_report(Y_test, grid_predictions))
